{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenEXR numpy pillow"
      ],
      "metadata": {
        "id": "taCtlUPh2rhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python==4.5.4.58"
      ],
      "metadata": {
        "id": "Bry34b1S3iHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import OpenEXR\n",
        "import Imath\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import imageio.v2 as imageio\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import img_to_array\n",
        "#from keras import backend as K\n",
        "#from tensorflow.keras.utils import img_to_array\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Input\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import Activation, Reshape\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import add\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Model\n",
        "import keras.optimizers\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import MaxPooling2D, UpSampling2D\n"
      ],
      "metadata": {
        "id": "-qdG-YRByUEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segnet(input_shape, n_labels, kernel=3, pool_size=(2, 2), output_mode=\"softmax\"):\n",
        "    # encoder\n",
        "    inputs = Input(shape=input_shape)\n",
        "    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n",
        "    conv_1 = BatchNormalization()(conv_1)\n",
        "    conv_1 = Activation(\"relu\")(conv_1)\n",
        "    residual = conv_1\n",
        "    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n",
        "    conv_2 = BatchNormalization()(conv_2)\n",
        "    conv_2 = Dropout(0.3)(conv_2)\n",
        "    conv_2 = Activation(\"relu\")(conv_2)\n",
        "    residual = Convolution2D(64, (kernel, kernel), padding=\"same\")(residual)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    conv_2 = add([conv_2,residual])\n",
        "\n",
        "\n",
        "    pool_1 = MaxPooling2D(pool_size=pool_size, strides=pool_size, padding=\"same\")(conv_2)\n",
        "\n",
        "    residual = pool_1\n",
        "    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n",
        "    conv_3 = BatchNormalization()(conv_3)\n",
        "    conv_3 = Activation(\"relu\")(conv_3)\n",
        "    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n",
        "    conv_4 = BatchNormalization()(conv_4)\n",
        "    conv_4 = Dropout(0.3)(conv_4)\n",
        "    conv_4 = Activation(\"relu\")(conv_4)\n",
        "    residual = Convolution2D(128, (kernel, kernel), padding=\"same\")(residual)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    conv_4 = add([conv_4,residual])\n",
        "\n",
        "    pool_2 = MaxPooling2D(pool_size=pool_size, strides=pool_size, padding=\"same\")(conv_4)\n",
        "\n",
        "    residual = pool_2\n",
        "    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n",
        "    conv_5 = BatchNormalization()(conv_5)\n",
        "    conv_5 = Activation(\"relu\")(conv_5)\n",
        "    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n",
        "    conv_6 = BatchNormalization()(conv_6)\n",
        "    conv_6 = Dropout(0.3)(conv_6)\n",
        "    conv_6 = Activation(\"relu\")(conv_6)\n",
        "    residual = Convolution2D(256, (kernel, kernel), padding=\"same\")(residual)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    conv_6 = add([conv_6,residual])\n",
        "\n",
        "    pool_3 = MaxPooling2D(pool_size=pool_size, strides=pool_size, padding=\"same\")(conv_6)\n",
        "\n",
        "    residual = pool_3\n",
        "    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n",
        "    conv_8 = BatchNormalization()(conv_8)\n",
        "    conv_8 = Dropout(0.3)(conv_8)\n",
        "    conv_8 = Activation(\"relu\")(conv_8)\n",
        "    residual = Convolution2D(512, (kernel, kernel), padding=\"same\")(residual)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    conv_8 = add([conv_8,residual])\n",
        "\n",
        "    pool_4 = MaxPooling2D(pool_size=pool_size, strides=pool_size, padding=\"same\")(conv_8)\n",
        "\n",
        "    residual = pool_4\n",
        "    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n",
        "    conv_11 = BatchNormalization()(conv_11)\n",
        "    conv_11 = Dropout(0.3)(conv_11)\n",
        "    conv_11 = Activation(\"relu\")(conv_11)\n",
        "    residual = Convolution2D(512, (kernel, kernel), padding=\"same\")(residual)\n",
        "    residual = BatchNormalization()(residual)\n",
        "    conv_11 = add([conv_11,residual])\n",
        "\n",
        "    pool_5 = MaxPooling2D(pool_size=pool_size, strides=pool_size, padding=\"same\")(conv_11)\n",
        "\n",
        "    # decoder\n",
        "    unpool_1 = UpSampling2D(size=pool_size, interpolation=\"bilinear\")(pool_5)\n",
        "\n",
        "\n",
        "    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n",
        "    conv_14 = BatchNormalization()(conv_14)\n",
        "    conv_14 = Dropout(0.3)(conv_14)\n",
        "    conv_14 = Activation(\"relu\")(conv_14)\n",
        "\n",
        "    unpool_2 = UpSampling2D(size=pool_size, interpolation=\"bilinear\")(conv_14)\n",
        "\n",
        "    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n",
        "    conv_17 = BatchNormalization()(conv_17)\n",
        "    conv_17 = Activation(\"relu\")(conv_17)\n",
        "    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_17)\n",
        "    conv_19 = BatchNormalization()(conv_19)\n",
        "    conv_19 = Dropout(0.3)(conv_19)\n",
        "    conv_19 = Activation(\"relu\")(conv_19)\n",
        "\n",
        "    unpool_3 = UpSampling2D(size=pool_size, interpolation=\"bilinear\")(conv_19)\n",
        "\n",
        "    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n",
        "    conv_20 = BatchNormalization()(conv_20)\n",
        "    conv_20 = Activation(\"relu\")(conv_20)\n",
        "    conv_21 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_20)\n",
        "    conv_21 = BatchNormalization()(conv_21)\n",
        "    conv_21 = Dropout(0.3)(conv_21)\n",
        "    conv_21 = Activation(\"relu\")(conv_21)\n",
        "\n",
        "\n",
        "    unpool_4 = UpSampling2D(size=pool_size, interpolation=\"bilinear\")(conv_21)\n",
        "\n",
        "    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n",
        "    conv_23 = BatchNormalization()(conv_23)\n",
        "    conv_23 = Activation(\"relu\")(conv_23)\n",
        "    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n",
        "    conv_24 = BatchNormalization()(conv_24)\n",
        "    conv_24 = Dropout(0.3)(conv_24)\n",
        "    conv_24 = Activation(\"relu\")(conv_24)\n",
        "\n",
        "\n",
        "    unpool_5 = UpSampling2D(size=pool_size, interpolation=\"bilinear\")(conv_24)\n",
        "\n",
        "    residual = unpool_5\n",
        "    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n",
        "    conv_25 = BatchNormalization()(conv_25)\n",
        "    conv_25 = Activation(\"relu\")(conv_25)\n",
        "\n",
        "    conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_25)\n",
        "    conv_26 = BatchNormalization()(conv_26)\n",
        "    conv_26 = Reshape(\n",
        "        (input_shape[0], input_shape[1], n_labels),\n",
        "        input_shape=(input_shape[0], input_shape[1], n_labels),\n",
        "    )(conv_26)\n",
        "    outputs = Activation(output_mode)(conv_26)\n",
        "    print(\"Build decoder done..\")\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = segnet((224,224,3), n_labels=5 ,kernel=3, pool_size=(2,2), output_mode=\"softmax\")\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "print(\"tf.__version__ is\", tf.__version__)"
      ],
      "metadata": {
        "id": "rGmFNaKlydHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def exr_to_jpg(path):\n",
        "    exr_file = OpenEXR.InputFile(path)\n",
        "\n",
        "    header = exr_file.header()\n",
        "    data_window = header['dataWindow']\n",
        "    width = data_window.max.x - data_window.min.x + 1\n",
        "    height = data_window.max.y - data_window.min.y + 1\n",
        "\n",
        "\n",
        "    channels = [\"R\",\"G\",\"B\"]\n",
        "    data = [np.frombuffer(exr_file.channel(channel, Imath.PixelType(Imath.PixelType.FLOAT)), dtype=np.float32)\n",
        "                for channel in channels]\n",
        "\n",
        "    array = [np.clip(channel.reshape(height, width)/(np.max(channel)+ 1e-7),0,1).astype(np.float32) for channel in data]\n",
        "\n",
        "    image = np.dstack(array)\n",
        "    return image\n",
        "\n",
        "def category_label(labels, dims, n_labels):\n",
        "    x = np.zeros([dims[0], dims[1], n_labels])\n",
        "    for i in range(dims[0]):\n",
        "        for j in range(dims[1]):\n",
        "            f=int(labels[i,j])\n",
        "            x[i, j, f] = 1\n",
        "    return x\n",
        "def colorize(img):\n",
        "    w=img.shape[0]\n",
        "    h=img.shape[1]\n",
        "    z=img.shape[2]\n",
        "    l=np.zeros((w,h,3))\n",
        "    for i in range(w):\n",
        "        for j in range(h):\n",
        "            if img[i,j,0]==1:\n",
        "                l[i,j,0]=0\n",
        "                l[i,j,1]=0\n",
        "                l[i,j,2]=0\n",
        "            elif img[i,j,1]==1:\n",
        "                l[i,j,0]=255\n",
        "                l[i,j,1]=0\n",
        "                l[i,j,2]=0\n",
        "            elif img[i,j,2]==1:\n",
        "                l[i,j,0]=0\n",
        "                l[i,j,1]=255\n",
        "                l[i,j,2]=0\n",
        "            elif img[i,j,3]==1:\n",
        "                l[i,j,0]=0\n",
        "                l[i,j,1]=0\n",
        "                l[i,j,2]=255\n",
        "            elif img[i,j,4]==1:\n",
        "                l[i,j,0]=238\n",
        "                l[i,j,1]=197\n",
        "                l[i,j,2]=145\n",
        "    return l\n",
        "\n",
        "def class_pixels(img):\n",
        "    w=img.shape[0]\n",
        "    h=img.shape[1]\n",
        "    z=img.shape[2]\n",
        "    l=np.zeros((w,h,z))\n",
        "    for i in range(w):\n",
        "        for j in range(h):\n",
        "            for f in range(z-1):\n",
        "                if img[i,j,f]==np.max([img[i,j,0],img[i,j,1],img[i,j,2],img[i,j,3],img[i,j,4]]):\n",
        "                    l[i,j,f]=1\n",
        "    return l\n"
      ],
      "metadata": {
        "id": "Vj3sGhxT0EpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "\n",
        "def process_file(index, img_dir, mask_dir, dims, n_labels):\n",
        "    img_path = img_dir[index]\n",
        "    original_img = exr_to_jpg(img_path)\n",
        "    array_img = img_to_array(original_img) / 255.0\n",
        "\n",
        "    mask_path = mask_dir[index]\n",
        "    original_mask = cv2.imread(mask_path, cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
        "    array_mask = category_label(original_mask[:, :, 0], dims, n_labels)\n",
        "\n",
        "    return array_img, array_mask\n",
        "\n",
        "def data_gen_small(img_dir, mask_dir, depth_dir, liste, batch_size, dims=(224, 224), n_labels=5):\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        while True:\n",
        "            ix = np.random.choice(liste, batch_size)\n",
        "            results = list(executor.map(\n",
        "                lambda index: process_file(index, img_dir, mask_dir, dims, n_labels), ix\n",
        "            ))\n",
        "\n",
        "            imgs, labels = zip(*results)\n",
        "            yield np.array(imgs), np.array(labels)"
      ],
      "metadata": {
        "id": "62MgWY1bYxdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "rgb=[]\n",
        "depth=[]\n",
        "mask=[]\n",
        "node=[]\n",
        "for dirs,subdir,files in os.walk('/content/dataset of synthetic rgb-d plants/rgb_map'):\n",
        "    for file_name in files:\n",
        "      if file_name.endswith(\".exr\"):\n",
        "            path_file=dirs+os.sep+file_name\n",
        "            depth_file='/content/dataset of synthetic rgb-d plants/depth_map/profondeur_map/'+file_name\n",
        "            mask_file='/content/dataset of synthetic rgb-d plants/semantic_map/segmentation2_map/'+file_name\n",
        "            node_file='/content/dataset of synthetic rgb-d plants/nodes_map/internoeuds_map/'+file_name\n",
        "            rgb.append(path_file)\n",
        "            depth.append(depth_file)\n",
        "            mask.append(mask_file)\n",
        "            node.append(node_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "liste=np.arange(1,10000)\n",
        "np.random.shuffle(liste)\n",
        "\n",
        "train_list=liste[0:8000]\n",
        "val_list=liste[8000:9000]\n",
        "test_list=liste[9000:9999]\n",
        "\n",
        "\n",
        "train_gen = data_gen_small(rgb\n",
        ",mask,depth,liste=train_list,batch_size=32,dims=(224,224),n_labels=5)\n",
        "val_gen=data_gen_small(rgb\n",
        ",mask,depth,liste=val_list,batch_size=32,dims=(224,224),n_labels=5)\n",
        "test_gen = data_gen_small(rgb\n",
        ",mask,depth,liste=test_list,batch_size=1,dims=(224,224),n_labels=5)\n",
        "\n",
        "\n",
        "input_shape = (224, 224, 3)\n",
        "output_shape = (224, 224, 5)\n",
        "def train_gen_wrapper():\n",
        "    return data_gen_small(rgb, mask, depth, liste=train_list, batch_size=16, dims=(224, 224), n_labels=5)\n",
        "def val_gen_wrapper():\n",
        "    return data_gen_small(rgb, mask, depth, liste=val_list, batch_size=16, dims=(224, 224), n_labels=5)\n",
        "def test_gen_wrapper():\n",
        "    return data_gen_small(rgb, mask, depth, liste=test_list, batch_size=1, dims=(224, 224), n_labels=5)\n",
        "\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    train_gen_wrapper,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(16, *input_shape), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(16, *output_shape), dtype=tf.float32),\n",
        "    )\n",
        ")\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_generator(\n",
        "    val_gen_wrapper,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(16, *input_shape), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(16, *output_shape), dtype=tf.float32),\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_generator(\n",
        "    test_gen_wrapper,\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(1, *input_shape), dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=(1, *output_shape), dtype=tf.float32),\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "73pnW6FD0IU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = K.reshape(y_true, K.shape(y_pred))\n",
        "    epsilon=1e-6\n",
        "    axes = tuple(range(1, len(y_pred.shape)-1))\n",
        "    numerator = 2. * K.sum(y_pred * y_true, axes)\n",
        "    denominator = K.sum(K.square(y_pred) + K.square(y_true), axes)\n",
        "\n",
        "    return K.mean((numerator + epsilon) / (denominator + epsilon))\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "7hH8e0Rw0JYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=dice_coef_loss, optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\", dice_coef])"
      ],
      "metadata": {
        "id": "BgRVbuqAyjFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.prefetch(buffer_size = tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "-is7EC4z1wzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    dataset,\n",
        "    steps_per_epoch=100,\n",
        "    epochs=50,\n",
        "    validation_data=val_dataset,\n",
        "    validation_steps=20,\n",
        ")\n"
      ],
      "metadata": {
        "id": "Vjgela2p0SeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'],markersize=20)\n",
        "plt.plot(history.history['val_accuracy'], markersize=20)\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()\n",
        "# plotting of training and validation loss curves\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "we9VEhid0dx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_exr_to_rgb(exr_path):\n",
        "    exr_file = OpenEXR.InputFile(exr_path)\n",
        "\n",
        "    header = exr_file.header()\n",
        "    data_window = header['dataWindow']\n",
        "    width = data_window.max.x - data_window.min.x + 1\n",
        "    height = data_window.max.y - data_window.min.y + 1\n",
        "\n",
        "    channels = ['R', 'G', 'B']\n",
        "    rgb_data = [np.frombuffer(exr_file.channel(channel, Imath.PixelType(Imath.PixelType.FLOAT)), dtype=np.float32)\n",
        "                for channel in channels]\n",
        "\n",
        "    rgb_array = [np.clip(channel.reshape(height, width) * 255, 0, 255).astype(np.uint8) for channel in rgb_data]\n",
        "\n",
        "    # Создаем RGB изображение из каналов\n",
        "    rgb_image = np.dstack(rgb_array)\n",
        "    return rgb_image"
      ],
      "metadata": {
        "id": "fLUP80Jp0r5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h=0\n",
        "for i in test_list:\n",
        "    if h<10:\n",
        "\n",
        "        img_path = rgb[i]\n",
        "        original_img = convert_exr_to_rgb(img_path)\n",
        "        # original_img = cv2.imread('/content/drive/MyDrive/Colab Notebooks/res.png')\n",
        "        # original_img = original_img[:224,:224,[2,1,0]]\n",
        "\n",
        "        plt.figure(figsize=(15,15))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.imshow(original_img)\n",
        "        array_img=img_to_array(original_img)/255\n",
        "\n",
        "        array_img2 = np.reshape(array_img, (1,224,224,3))\n",
        "        y_pred=model.predict(array_img2)\n",
        "        y_pred = np.reshape(y_pred[0], (224, 224, 5))\n",
        "        c=class_pixels(y_pred)\n",
        "        o=colorize(c)\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.imshow(o)\n",
        "        plt.show()\n",
        "        h+=1\n",
        "        print(\"Original Image Shape:\", array_img.shape)\n",
        "        print(\"Predicted Shape:\", y_pred.shape)\n",
        "        print(\"Class Pixels Shape:\", c.shape)\n",
        "        print(\"Colorized Output Shape:\", o.shape)\n",
        "\n",
        "    else:\n",
        "        break"
      ],
      "metadata": {
        "id": "WqRkb-EO0uCf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}